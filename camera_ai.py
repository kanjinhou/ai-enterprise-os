import cv2
import math
import time
import requests
import os
import numpy as np
import face_recognition
from ultralytics import YOLO

# --- é…ç½®éƒ¨åˆ† ---
SERVER_URL = "http://127.0.0.1:8000/api/v1/ppe/events/"
CAMERA_ID = "CAM-01"
CONFIDENCE_THRESHOLD = 0.5
FACE_DB_DIR = "authorized_faces"

# API è®¤è¯ä¿¡æ¯
USERNAME = "admin"
PASSWORD = "admin123"

# --- 1. åŠ è½½äººè„¸æ•°æ®åº“ (å¸¦å†…å­˜ä¿®å¤) ---
print(f"ğŸ”„ Loading Employee Database from '{FACE_DB_DIR}'...")
known_face_encodings = []
known_face_names = []
known_face_ids = []

if not os.path.exists(FACE_DB_DIR):
    os.makedirs(FACE_DB_DIR)
    print(f"âš ï¸ Warning: Directory '{FACE_DB_DIR}' created. Please put photos there!")
else:
    for filename in os.listdir(FACE_DB_DIR):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            try:
                # è§£ææ–‡ä»¶å
                name_part = os.path.splitext(filename)[0]
                if "_" in name_part:
                    emp_id, emp_name = name_part.split("_", 1)
                else:
                    emp_id, emp_name = "N/A", name_part
                
                image_path = os.path.join(FACE_DB_DIR, filename)
                
                # [å…³é”®ä¿®å¤ 1] åŠ è½½å›¾ç‰‡åï¼Œå¼ºåˆ¶è½¬ä¸ºè¿ç»­å†…å­˜
                image = face_recognition.load_image_file(image_path)
                image = np.ascontiguousarray(image) 
                
                # è·å–ç‰¹å¾
                encodings = face_recognition.face_encodings(image)
                
                if len(encodings) > 0:
                    known_face_encodings.append(encodings[0])
                    known_face_names.append(emp_name)
                    known_face_ids.append(emp_id)
                    print(f"  âœ… Loaded Identity: {emp_name} (ID: {emp_id})")
                else:
                    print(f"  âš ï¸ No face found in {filename}")
                    
            except Exception as e:
                print(f"  âŒ Error loading {filename}: {e}")

print(f"âœ… Database Ready. Total profiles: {len(known_face_names)}")

# --- 2. åŠ è½½ YOLO æ¨¡å‹ ---
print("ğŸ”„ Loading YOLOv8 Model...")
model = YOLO("yolov8n.pt") 
classNames = model.names 

cap = cv2.VideoCapture(0)
cap.set(3, 1280)
cap.set(4, 720)

print("ğŸš€ Surveillance System Started!")

while True:
    success, img = cap.read()
    if not success or img is None:
        continue 

    # === A. äººè„¸è¯†åˆ«å¤„ç† (Face Recognition) ===
    # ç¼©å°å›¾ç‰‡
    img_small = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)
    
    # [å…³é”®ä¿®å¤ 2] BGR è½¬ RGB åï¼Œå†æ¬¡å¼ºåˆ¶è½¬ä¸ºè¿ç»­å†…å­˜ï¼Œé˜²æ­¢ dlib å´©æºƒ
    rgb_small_frame = img_small[:, :, ::-1]
    rgb_small_frame = np.ascontiguousarray(rgb_small_frame)

    # æŸ¥æ‰¾äººè„¸
    try:
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

        current_persons = [] 

        for face_encoding, face_loc in zip(face_encodings, face_locations):
            name = "Unknown"
            emp_id = "N/A"
            
            # åªæœ‰å½“æ•°æ®åº“ä¸ä¸ºç©ºæ—¶æ‰è¿›è¡Œæ¯”å¯¹
            if len(known_face_encodings) > 0:
                matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                
                if len(face_distances) > 0:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        name = known_face_names[best_match_index]
                        emp_id = known_face_ids[best_match_index]
            
            current_persons.append({'name': name, 'id': emp_id})

            # ç”»æ¡† (è½¬æ¢åæ ‡å›åŸå›¾)
            top, right, bottom, left = face_loc
            top *= 4; right *= 4; bottom *= 4; left *= 4 
            cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(img, f"{name}", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
    except Exception as e:
        # å¦‚æœäººè„¸è¯†åˆ«å¶å°”å‡ºé”™ï¼Œæ‰“å°ä½†ä¸å´©æºƒ
        print(f"Face Rec Error: {e}")
        current_persons = []

    # === B. YOLO ç‰©ä½“æ£€æµ‹ ===
    results = model(img, stream=True, verbose=False)
    violation_detected = False
    violation_type = ""

    for r in results:
        boxes = r.boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            conf = math.ceil((box.conf[0] * 100)) / 100
            cls = int(box.cls[0])
            label = classNames[cls]

            if conf > CONFIDENCE_THRESHOLD:
                color = (255, 0, 0)
                # æ¼”ç¤ºé€»è¾‘: æ£€æµ‹åˆ°äººä¸”æŒ‰Sé”®æ—¶
                if label == "person": 
                    violation_detected = True
                    violation_type = "No Safety Gear"
                    color = (0, 0, 255)

                cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)
                cv2.putText(img, f'{label} {conf}', (max(0, x1), max(35, y1)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # === C. æ˜¾ç¤ºä¸ä¸Šä¼  ===
    who_is_it = "Unknown"
    who_id = "N/A"
    if 'current_persons' in locals() and len(current_persons) > 0:
        who_is_it = current_persons[0]['name']
        who_id = current_persons[0]['id']

    status_text = f"ID: {who_is_it} | Check: {violation_detected}"
    cv2.putText(img, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

    cv2.imshow("AI Enterprise OS - Camera 01", img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    
    # æŒ‰ 's' é”®æ‰‹åŠ¨è§¦å‘æŠ¥è­¦
    if key == ord('s') and violation_detected:
        print(f"ğŸš€ Reporting Violation for: {who_is_it}...")
        try:
            _, img_encoded = cv2.imencode('.jpg', img)
            files = {'image': ('capture.jpg', img_encoded.tobytes(), 'image/jpeg')}
            data = {
                'camera_id': CAMERA_ID,
                'detections': '{"items": [{"class": "' + violation_type + '", "confidence": 0.95}]}',
                'person_name': who_is_it,
                'person_id': who_id
            }
            # å‘é€è¯·æ±‚ï¼ˆå¸¦è®¤è¯ï¼‰
            response = requests.post(SERVER_URL, data=data, files=files, auth=(USERNAME, PASSWORD))
            if response.status_code in [200, 201]:
                print("âœ… Alert Sent to Django!")
            else:
                print(f"âŒ Upload Failed: {response.status_code} - {response.text[:200]}")
        except Exception as e:
            print(f"âŒ Upload Failed: {e}")

cap.release()
cv2.destroyAllWindows()
