"""
LLM æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆå™¨
åŸºäºå½“æ—¥è¿è§„æ•°æ®ç”Ÿæˆ Markdown æ ¼å¼çš„å®‰å…¨æŠ¥å‘Šï¼ˆæ¥å…¥ OpenAI/DeepSeek APIï¼‰
"""
import json
import requests
from collections import Counter

from django.conf import settings
from django.utils import timezone

# ä½¿ç”¨ DetectionEventï¼ˆppe åº”ç”¨ä¸­çš„æ£€æµ‹äº‹ä»¶æ¨¡å‹ï¼‰
from ppe.models import DetectionEvent


def _normalize_violation_label(raw: str) -> str:
    """å°† raw è¿è§„ç±»å‹è½¬ä¸ºå¯è¯»æ ‡ç­¾ï¼Œå¦‚ no_helmet -> No Helmet"""
    if not raw:
        return "Unknown"
    s = str(raw).strip().lower().replace("_", " ").replace("-", " ")
    return s.title() if s else "Unknown"


def _extract_violations_from_detections(detections) -> list[str]:
    """
    ä» detections JSON ä¸­æå–è¿è§„ç±»å‹åˆ—è¡¨ã€‚
    æ”¯æŒæ ¼å¼: {'items': [{'class': '...'}, ...]} æˆ– {'violation': '...'} æˆ–å•æ¡ {'class': '...'}
    """
    out = []
    if not isinstance(detections, dict):
        return out
    items = detections.get("items")
    if items and isinstance(items, list):
        for it in items:
            if isinstance(it, dict):
                label = it.get("class") or it.get("violation")
                if label:
                    out.append(str(label).strip())
    else:
        label = detections.get("class") or detections.get("violation")
        if label:
            out.append(str(label).strip())
    return out


def generate_daily_report(customer):
    """
    ç”ŸæˆæŒ‡å®šå®¢æˆ·å½“æ—¥çš„å®‰å…¨æŠ¥å‘Šï¼ˆMarkdown æ–‡æœ¬ï¼‰ã€‚
    æ•°æ®æ¥æº: DetectionEventï¼ˆå½“æ—¥ã€è¯¥å®¢æˆ·ï¼‰ã€‚
    """
    today = timezone.now().date()
    events = DetectionEvent.objects.filter(
        customer=customer,
        timestamp__date=today,
    ).order_by("-timestamp")

    total_violations = 0
    type_counts: Counter = Counter()
    camera_counts: Counter = Counter()

    for ev in events:
        camera_counts[ev.camera_id] += 1
        violations = _extract_violations_from_detections(ev.detections)
        if violations:
            for v in violations:
                type_counts[_normalize_violation_label(v)] += 1
                total_violations += 1
        else:
            # æ— å…·ä½“ç±»å‹æ—¶ï¼ŒæŒ‰äº‹ä»¶è®¡ä¸º 1 æ¬¡è¿è§„
            type_counts["General"] += 1
            total_violations += 1

    # è¿è§„æœ€å¤šçš„æ‘„åƒå¤´
    hotspot_camera = ""
    if camera_counts:
        hotspot_camera = camera_counts.most_common(1)[0][0]

    # åˆè§„ç¨‹åº¦æè¿°ï¼ˆåŸºäºå½“æ—¥è¿è§„æ•°ç®€å•åˆ†çº§ï¼‰
    if total_violations == 0:
        compliance_desc = "Excellent"
    elif total_violations <= 3:
        compliance_desc = "Good"
    elif total_violations <= 10:
        compliance_desc = "Moderate"
    else:
        compliance_desc = "Low"

    # æŒ‰æ•°é‡æ’åºçš„è¿è§„ç±»å‹
    sorted_types = type_counts.most_common()
    key_violations_lines = []
    for label, cnt in sorted_types:
        emphasis = " (Critical!)" if cnt >= 3 else ""
        key_violations_lines.append(f"- **{label}**: {cnt} incident(s){emphasis}")

    key_violations_md = "\n".join(key_violations_lines) if key_violations_lines else "- No specific violation types recorded."

    hotspot_md = (
        f"Most violations occurred at **{hotspot_camera}**. Please inspect this area."
        if hotspot_camera
        else "No camera hotspot data available for today."
    )

    if total_violations == 0:
        summary = "Today, we detected **no violations**. The safety compliance level is **Excellent**."
    else:
        summary = f"Today, we detected a total of **{total_violations}** violation(s). The safety compliance level is **{compliance_desc}**."

    # æ„å»ºæ•°æ®æ‘˜è¦ï¼ˆç”¨äº LLM Promptï¼‰
    violations_detail = ", ".join([f"{label}: {cnt}" for label, cnt in sorted_types]) if sorted_types else "None"
    
    # å°è¯•è°ƒç”¨ LLM API ç”ŸæˆæŠ¥å‘Š
    llm_report = _generate_report_with_llm(
        customer_name=customer.name,
        date=today.strftime('%Y-%m-%d'),
        total_violations=total_violations,
        compliance_desc=compliance_desc,
        violations_detail=violations_detail,
        hotspot_camera=hotspot_camera,
        key_violations_md=key_violations_md,
        hotspot_md=hotspot_md,
    )
    
    # å¦‚æœ LLM è°ƒç”¨æˆåŠŸï¼Œè¿”å› AI ç”Ÿæˆçš„æŠ¥å‘Šï¼›å¦åˆ™ä½¿ç”¨æ¨¡æ¿æŠ¥å‘Š
    if llm_report:
        return llm_report
    
    # Fallback: ä½¿ç”¨ç¡¬ç¼–ç æ¨¡æ¿
    report = f"""## ğŸ›¡ï¸ Daily Safety Report - {customer.name}
**Date**: {today.strftime('%Y-%m-%d')}

### ğŸ“Š Summary
{summary}

### ğŸš« Key Violations
{key_violations_md}

### ğŸ“ Hotspots
{hotspot_md}

---
*Generated by AI Enterprise OS*
"""
    return report.strip()


def _generate_report_with_llm(customer_name, date, total_violations, compliance_desc, 
                                violations_detail, hotspot_camera, key_violations_md, hotspot_md):
    """
    è°ƒç”¨ LLM API ç”ŸæˆæŠ¥å‘Š
    
    Returns:
        str: AI ç”Ÿæˆçš„æŠ¥å‘Šæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰ API Key
    api_key = getattr(settings, 'LLM_API_KEY', None)
    if not api_key or api_key == '':
        print("[Report Generator] No LLM API key configured, using template fallback")
        return None
    
    api_base = getattr(settings, 'LLM_API_BASE', 'https://api.openai.com/v1')
    model = getattr(settings, 'LLM_MODEL', 'gpt-4o-mini')
    
    # æ„å»º Prompt (English)
    prompt = f"""You are a professional Safety Officer at a factory. Analyze the following violation data and generate a concise Daily Safety Report in Markdown format.

**Data Summary:**
- Customer Name: {customer_name}
- Date: {date}
- Total Violations: {total_violations}
- Compliance Level: {compliance_desc}
- Violation Details: {violations_detail}
- Hotspot Camera: {hotspot_camera if hotspot_camera else "None"}

**Requirements:**
1. Use Markdown format
2. Include sections: Title, Summary, Key Violations, Hotspots
3. Professional but clear language
4. If violations = 0, emphasize excellent safety performance
5. If violations exist, provide constructive recommendations
6. Use appropriate emojis for readability
7. **IMPORTANT: Generate the entire report in English only**

Please generate the report:"""
    
    # å‡†å¤‡è¯·æ±‚
    # DeepSeek API ç«¯ç‚¹: https://api.deepseek.com/chat/completions
    # ç¡®ä¿ URL æ‹¼æ¥æ­£ç¡®ï¼ˆç§»é™¤æœ«å°¾æ–œæ ï¼Œç„¶åæ·»åŠ  /chat/completionsï¼‰
    url = f"{api_base.rstrip('/')}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,  # ä½¿ç”¨ settings.LLM_MODELï¼ˆdeepseek-chatï¼‰
        "messages": [
            {
                "role": "system",
                "content": "You are a professional Safety Officer at a factory. Analyze violation data and generate concise Daily Safety Reports in Markdown format. Use professional tone. English only."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1000,
        "stream": False  # DeepSeek æ”¯æŒæµå¼ï¼Œè¿™é‡Œè®¾ä¸º False è·å–å®Œæ•´å“åº”
    }
    
    try:
        print(f"[Report Generator] Calling LLM API: {url} (model: {model})")
        # 120 ç§’è¶…æ—¶ï¼šæœ¬åœ° Ollama å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œç»™äºˆ 2 åˆ†é’Ÿç­‰å¾…æ—¶é—´
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        
        # æå–ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
        if 'choices' in result and len(result['choices']) > 0:
            report_content = result['choices'][0]['message']['content']
            print("[Report Generator] LLM report generated successfully")
            return report_content.strip()
        else:
            print("[Report Generator] Invalid response format from LLM API")
            return None
            
    except requests.exceptions.Timeout:
        print(f"[Report Generator] LLM API request timeout (120s exceeded)")
        return None
    except requests.exceptions.RequestException as e:
        print(f"[Report Generator] LLM API request failed: {e}")
        return None
    except (KeyError, IndexError, json.JSONDecodeError) as e:
        print(f"[Report Generator] Failed to parse LLM response: {e}")
        return None
    except Exception as e:
        print(f"[Report Generator] Unexpected error: {e}")
        return None
